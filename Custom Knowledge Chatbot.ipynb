{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6337c0b",
   "metadata": {},
   "source": [
    "# Custom Knowledge Chatbot w/ LlamaIndex\n",
    "By Liam Ottley - YouTube: https://www.youtube.com/@LiamOttley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8911e71",
   "metadata": {},
   "source": [
    "Examples:\n",
    "- https://gita.kishans.in/\n",
    "- https://www.chatpdf.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c425f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.6)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.5.14)\n",
      "Requirement already satisfied: langchain<=0.0.266,>=0.0.262 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.0.266)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.15 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (2.0.20)\n",
      "Requirement already satisfied: numpy in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (1.25.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (8.2.3)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.27.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (2.0.3)\n",
      "Requirement already satisfied: urllib3<2 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (1.26.16)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (2023.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (4.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama_index) (4.12.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\swaroopdamodaran\\appdata\\roaming\\python\\python311\\site-packages (from llama_index) (1.5.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama_index) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama_index) (3.8.5)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama_index) (0.0.26)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama_index) (2.8.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama_index) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama_index) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama_index) (2.31.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama_index) (3.20.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=0.26.4->llama_index) (4.66.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=2.0.15->llama_index) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->llama_index) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\swaroopdamodaran\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama_index) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama_index) (2023.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken->llama_index) (2023.8.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama_index) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama_index) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama_index) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama_index) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama_index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama_index) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama_index) (1.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\swaroopdamodaran\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\swaroopdamodaran\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama_index) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain<=0.0.266,>=0.0.262->llama_index) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain<=0.0.266,>=0.0.262->llama_index) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\swaroopdamodaran\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai>=0.26.4->llama_index) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76406293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "     -                                        0.1/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -                                        0.1/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -                                        0.1/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -                                        0.1/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     -                                        0.1/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     --                                       0.1/1.5 MB 308.0 kB/s eta 0:00:05\n",
      "     -----                                    0.2/1.5 MB 687.0 kB/s eta 0:00:02\n",
      "     -------                                  0.3/1.5 MB 737.3 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     ----------                               0.4/1.5 MB 933.2 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.5 MB 583.4 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.5 MB 583.4 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.5 MB 583.4 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.5 MB 583.4 kB/s eta 0:00:02\n",
      "     -------------                            0.5/1.5 MB 583.4 kB/s eta 0:00:02\n",
      "     --------------                           0.6/1.5 MB 512.9 kB/s eta 0:00:02\n",
      "     --------------                           0.6/1.5 MB 512.9 kB/s eta 0:00:02\n",
      "     --------------                           0.6/1.5 MB 512.9 kB/s eta 0:00:02\n",
      "     --------------                           0.6/1.5 MB 512.9 kB/s eta 0:00:02\n",
      "     --------------                           0.6/1.5 MB 512.9 kB/s eta 0:00:02\n",
      "     ----------------                         0.6/1.5 MB 473.7 kB/s eta 0:00:02\n",
      "     -----------------                        0.7/1.5 MB 484.1 kB/s eta 0:00:02\n",
      "     -------------------                      0.7/1.5 MB 504.1 kB/s eta 0:00:02\n",
      "     -------------------                      0.7/1.5 MB 500.4 kB/s eta 0:00:02\n",
      "     --------------------                     0.8/1.5 MB 501.6 kB/s eta 0:00:02\n",
      "     --------------------                     0.8/1.5 MB 497.9 kB/s eta 0:00:02\n",
      "     ---------------------                    0.8/1.5 MB 502.5 kB/s eta 0:00:02\n",
      "     ----------------------                   0.8/1.5 MB 505.4 kB/s eta 0:00:02\n",
      "     ----------------------                   0.9/1.5 MB 503.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 491.5 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 399.7 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 399.7 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 399.7 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 399.7 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 399.7 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 365.4 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 365.4 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 365.4 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 365.4 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 365.4 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 365.4 kB/s eta 0:00:02\n",
      "     -----------------------                  0.9/1.5 MB 365.4 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 327.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.9/1.5 MB 261.5 kB/s eta 0:00:03\n",
      "     ------------------------                 0.9/1.5 MB 261.5 kB/s eta 0:00:03\n",
      "     ------------------------                 0.9/1.5 MB 261.5 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 253.3 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 253.3 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 253.3 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 253.3 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 253.3 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 253.3 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 242.5 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 242.5 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 242.5 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 242.5 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 242.5 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 242.5 kB/s eta 0:00:03\n",
      "     -------------------------                1.0/1.5 MB 242.5 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 225.6 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 225.6 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 225.6 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 225.6 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 225.6 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 217.0 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 217.0 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 217.0 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 214.1 kB/s eta 0:00:03\n",
      "     --------------------------               1.0/1.5 MB 214.1 kB/s eta 0:00:03\n",
      "     ---------------------------              1.0/1.5 MB 214.2 kB/s eta 0:00:03\n",
      "     ---------------------------              1.0/1.5 MB 214.2 kB/s eta 0:00:03\n",
      "     ---------------------------              1.0/1.5 MB 214.2 kB/s eta 0:00:03\n",
      "     ---------------------------              1.0/1.5 MB 209.4 kB/s eta 0:00:03\n",
      "     ---------------------------              1.0/1.5 MB 209.4 kB/s eta 0:00:03\n",
      "     ----------------------------             1.1/1.5 MB 210.3 kB/s eta 0:00:03\n",
      "     ----------------------------             1.1/1.5 MB 210.3 kB/s eta 0:00:03\n",
      "     ----------------------------             1.1/1.5 MB 210.3 kB/s eta 0:00:03\n",
      "     ----------------------------             1.1/1.5 MB 207.2 kB/s eta 0:00:03\n",
      "     ----------------------------             1.1/1.5 MB 207.2 kB/s eta 0:00:03\n",
      "     -----------------------------            1.1/1.5 MB 207.3 kB/s eta 0:00:03\n",
      "     -----------------------------            1.1/1.5 MB 207.3 kB/s eta 0:00:03\n",
      "     -----------------------------            1.1/1.5 MB 205.0 kB/s eta 0:00:02\n",
      "     -----------------------------            1.1/1.5 MB 207.0 kB/s eta 0:00:02\n",
      "     -----------------------------            1.1/1.5 MB 207.0 kB/s eta 0:00:02\n",
      "     ------------------------------           1.1/1.5 MB 207.8 kB/s eta 0:00:02\n",
      "     ------------------------------           1.2/1.5 MB 207.9 kB/s eta 0:00:02\n",
      "     -------------------------------          1.2/1.5 MB 209.8 kB/s eta 0:00:02\n",
      "     -------------------------------          1.2/1.5 MB 209.9 kB/s eta 0:00:02\n",
      "     --------------------------------         1.2/1.5 MB 214.8 kB/s eta 0:00:02\n",
      "     --------------------------------         1.2/1.5 MB 214.8 kB/s eta 0:00:02\n",
      "     --------------------------------         1.2/1.5 MB 214.3 kB/s eta 0:00:02\n",
      "     ---------------------------------        1.3/1.5 MB 216.7 kB/s eta 0:00:02\n",
      "     ---------------------------------        1.3/1.5 MB 216.1 kB/s eta 0:00:02\n",
      "     ----------------------------------       1.3/1.5 MB 220.2 kB/s eta 0:00:01\n",
      "     ----------------------------------       1.3/1.5 MB 220.2 kB/s eta 0:00:01\n",
      "     ----------------------------------       1.3/1.5 MB 220.2 kB/s eta 0:00:01\n",
      "     -----------------------------------      1.3/1.5 MB 221.9 kB/s eta 0:00:01\n",
      "     -----------------------------------      1.4/1.5 MB 221.2 kB/s eta 0:00:01\n",
      "     -----------------------------------      1.4/1.5 MB 221.2 kB/s eta 0:00:01\n",
      "     ------------------------------------     1.4/1.5 MB 221.2 kB/s eta 0:00:01\n",
      "     ------------------------------------     1.4/1.5 MB 223.4 kB/s eta 0:00:01\n",
      "     ------------------------------------     1.4/1.5 MB 223.4 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.4/1.5 MB 221.2 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.4/1.5 MB 221.7 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.4/1.5 MB 222.2 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.4/1.5 MB 222.2 kB/s eta 0:00:01\n",
      "     --------------------------------------   1.5/1.5 MB 223.2 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 224.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 226.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 226.5 kB/s eta 0:00:00\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "                                              0.0/97.9 kB ? eta -:--:--\n",
      "     ----                                     10.2/97.9 kB ? eta -:--:--\n",
      "     -----------                            30.7/97.9 kB 435.7 kB/s eta 0:00:01\n",
      "     ---------------                        41.0/97.9 kB 393.8 kB/s eta 0:00:01\n",
      "     -----------------------                61.4/97.9 kB 409.6 kB/s eta 0:00:01\n",
      "     -----------------------------------    92.2/97.9 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 97.9/97.9 kB 400.5 kB/s eta 0:00:00\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "                                              0.0/302.2 kB ? eta -:--:--\n",
      "     -                                        10.2/302.2 kB ? eta -:--:--\n",
      "     -----                                 41.0/302.2 kB 487.6 kB/s eta 0:00:01\n",
      "     -----                                 41.0/302.2 kB 487.6 kB/s eta 0:00:01\n",
      "     --------                              71.7/302.2 kB 435.7 kB/s eta 0:00:01\n",
      "     -----------                           92.2/302.2 kB 476.3 kB/s eta 0:00:01\n",
      "     -------------                        112.6/302.2 kB 467.6 kB/s eta 0:00:01\n",
      "     --------------                       122.9/302.2 kB 423.5 kB/s eta 0:00:01\n",
      "     -----------------                    143.4/302.2 kB 404.6 kB/s eta 0:00:01\n",
      "     ------------------                   153.6/302.2 kB 398.2 kB/s eta 0:00:01\n",
      "     --------------------                 174.1/302.2 kB 402.6 kB/s eta 0:00:01\n",
      "     -----------------------              194.6/302.2 kB 406.0 kB/s eta 0:00:01\n",
      "     ------------------------             204.8/302.2 kB 377.1 kB/s eta 0:00:01\n",
      "     ------------------------             204.8/302.2 kB 377.1 kB/s eta 0:00:01\n",
      "     --------------------------           225.3/302.2 kB 362.0 kB/s eta 0:00:01\n",
      "     ----------------------------         235.5/302.2 kB 351.4 kB/s eta 0:00:01\n",
      "     ------------------------------       256.0/302.2 kB 357.2 kB/s eta 0:00:01\n",
      "     --------------------------------     276.5/302.2 kB 355.0 kB/s eta 0:00:01\n",
      "     -----------------------------------  297.0/302.2 kB 352.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 302.2/302.2 kB 352.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\swaroopdamodaran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\swaroopdamodaran\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041eae8",
   "metadata": {},
   "source": [
    "# Basic LlamaIndex Usage Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec6395b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf41880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load you data into 'Documents' a custom type by LlamaIndex\n",
    "\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('./data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98df5bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x176893c5c10 state=finished raised RateLimitError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\openai.py:167\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(list_of_text, engine, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 167\u001b[0m data \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, model\u001b[39m=\u001b[39;49mengine, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mdata\n\u001b[0;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m [d[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    138\u001b[0m (\n\u001b[0;32m    139\u001b[0m     deployment_id,\n\u001b[0;32m    140\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m     url,\n\u001b[0;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    288\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m )\n\u001b[1;32m--> 298\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Create an index of your documents\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorStoreIndex\n\u001b[1;32m----> 5\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex\u001b[39m.\u001b[39;49mfrom_documents(documents)\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base.py:102\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     docstore\u001b[39m.\u001b[39mset_document_hash(doc\u001b[39m.\u001b[39mget_doc_id(), doc\u001b[39m.\u001b[39mhash)\n\u001b[0;32m     98\u001b[0m nodes \u001b[39m=\u001b[39m service_context\u001b[39m.\u001b[39mnode_parser\u001b[39m.\u001b[39mget_nodes_from_documents(\n\u001b[0;32m     99\u001b[0m     documents, show_progress\u001b[39m=\u001b[39mshow_progress\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    103\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m    104\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[0;32m    105\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m    106\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    107\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:46\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[0;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override \u001b[39m=\u001b[39m store_nodes_override\n\u001b[1;32m---> 46\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     47\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m     48\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[0;32m     49\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m     50\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[0;32m     51\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m     52\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[39massert\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(nodes)\n\u001b[0;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[0;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:241\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_nodes\u001b[39m(\u001b[39mself\u001b[39m, nodes: Sequence[BaseNode]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexDict:\n\u001b[0;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[39m    NOTE: Overrides BaseIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m        VectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m        if vector store does not store text\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes)\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:229\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    227\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[0;32m    230\u001b[0m         index_struct, nodes, show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress\n\u001b[0;32m    231\u001b[0m     )\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:201\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nodes:\n\u001b[0;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m embedding_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_embedding_results(nodes, show_progress)\n\u001b[0;32m    202\u001b[0m new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(embedding_results)\n\u001b[0;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    205\u001b[0m     \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:111\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_embedding_results\u001b[1;34m(self, nodes, show_progress)\u001b[0m\n\u001b[0;32m    105\u001b[0m         id_to_embed_map[n\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m n\u001b[39m.\u001b[39membedding\n\u001b[0;32m    107\u001b[0m \u001b[39m# call embedding model to get embeddings\u001b[39;00m\n\u001b[0;32m    108\u001b[0m (\n\u001b[0;32m    109\u001b[0m     result_ids,\n\u001b[0;32m    110\u001b[0m     result_embeddings,\n\u001b[1;32m--> 111\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model\u001b[39m.\u001b[39;49mget_queued_text_embeddings(show_progress)\n\u001b[0;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result_ids, result_embeddings):\n\u001b[0;32m    113\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\base.py:213\u001b[0m, in \u001b[0;36mBaseEmbedding.get_queued_text_embeddings\u001b[1;34m(self, show_progress)\u001b[0m\n\u001b[0;32m    211\u001b[0m cur_batch_ids \u001b[39m=\u001b[39m [text_id \u001b[39mfor\u001b[39;00m text_id, _ \u001b[39min\u001b[39;00m cur_batch]\n\u001b[0;32m    212\u001b[0m cur_batch_texts \u001b[39m=\u001b[39m [text \u001b[39mfor\u001b[39;00m _, text \u001b[39min\u001b[39;00m cur_batch]\n\u001b[1;32m--> 213\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch_texts)\n\u001b[0;32m    214\u001b[0m result_ids\u001b[39m.\u001b[39mextend(cur_batch_ids)\n\u001b[0;32m    215\u001b[0m result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\openai.py:313\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_embeddings\u001b[39m(\u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m    307\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get text embeddings.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[39m    By default, this is a wrapper around _get_text_embedding.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m    Can be overriden for batch queries.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \n\u001b[0;32m    312\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    314\u001b[0m         texts,\n\u001b[0;32m    315\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_text_engine,\n\u001b[0;32m    316\u001b[0m         deployment_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment_name,\n\u001b[0;32m    317\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopenai_kwargs,\n\u001b[0;32m    318\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SwaroopDamodaran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[0;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x176893c5c10 state=finished raised RateLimitError>]"
     ]
    }
   ],
   "source": [
    "# Create an index of your documents\n",
    "\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "18731b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1448 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I think Facebook's LLaMa is a great step forward in democratizing access to large language models and advancing research in this subfield of AI. It is encouraging to see that they are making the model available at several sizes and providing a model card to detail how it was built in accordance with responsible AI practices. I am also glad to see that they are releasing the model under a noncommercial license to ensure integrity and prevent misuse.\n"
     ]
    }
   ],
   "source": [
    "# Query your index!\n",
    "\n",
    "response = index.query(\"What do you think of Facebook's LLaMa?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57864389",
   "metadata": {},
   "source": [
    "# Customize your LLM for different output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c726dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 1321 tokens\n"
     ]
    }
   ],
   "source": [
    "# Setup your LLM\n",
    "\n",
    "from llama_index import LLMPredictor, GPTSimpleVectorIndex, PromptHelper\n",
    "\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.1, model_name=\"text-davinci-002\"))\n",
    "\n",
    "# define prompt helper\n",
    "# set maximum input size\n",
    "max_input_size = 4096\n",
    "# set number of output tokens\n",
    "num_output = 256\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = 20\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
    "\n",
    "custom_LLM_index = GPTSimpleVectorIndex(\n",
    "    documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f359b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1369 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I think it's a great idea!\n"
     ]
    }
   ],
   "source": [
    "# Query your index!\n",
    "\n",
    "response = custom_LLM_index.query(\"What do you think of Facebook's LLaMa?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f4e5c",
   "metadata": {},
   "source": [
    "# Wikipedia Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4db9772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "\n",
    "loader = WikipediaReader()\n",
    "wikidocs = loader.load_data(pages=['Cyclone Freddy'])\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Cyclone_Freddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "941c9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 4103 tokens\n"
     ]
    }
   ],
   "source": [
    "wiki_index = GPTSimpleVectorIndex(wikidocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e4a4dd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 3844 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cyclone Freddy is a very intense tropical cyclone that affected the Mascarene Islands, Madagascar, Mozambique, and Zimbabwe in February 2023. It is the longest-lived tropical cyclone on record, surpassing Hurricane John's record of 31 days. Freddy was once a powerful cyclone that was classified as a Category 5-equivalent tropical cyclone by the Joint Typhoon Warning Center (JTWC). It caused widespread damage and at least 29 deaths in Madagascar, Mozambique, and Zimbabwe. In Madagascar, over 14,000 homes were affected, with 5,500 destroyed, 3,079 flooded, and at least 9,696 damaged. At least 24,358 people were displaced, and nearly 25,000 customers were left without power at the height of the cyclone. In Saint-Paul, 20 tons of mangoes were destroyed, and Highway RD48 in Salazie was closed due to a landslide. Eleven mobile sites maintained by Orange S.A. were knocked offline in Tampon, Saint-Louis, and Saint-Paul.\n"
     ]
    }
   ],
   "source": [
    "response = wiki_index.query(\"What is cyclone freddy?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea2acc",
   "metadata": {},
   "source": [
    "# Customer Support Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "19f396a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./asos').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cb30944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 12584 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "946c44ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1317 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In the United Arab Emirates, you have the option of signing up for ASOS Premier, which gives you free Standard and Express delivery all year round when you spend over 150 AED. It costs 200 AED and is valid on the order you purchase it on.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What premier service options do I have in the UAE?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77e646",
   "metadata": {},
   "source": [
    "# YouTube Video Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "89160742",
   "metadata": {},
   "outputs": [],
   "source": [
    "YoutubeTranscriptReader = download_loader(\"YoutubeTranscriptReader\")\n",
    "\n",
    "loader = YoutubeTranscriptReader()\n",
    "documents = loader.load_data(ytlinks=['https://www.youtube.com/watch?v=K7Kh9Ntd8VE&ab_channel=DaveNick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0995d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 18181 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "194e88fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 4024 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 8 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Re-uploading other people's content without permission.\n",
      "2. Using copyrighted music.\n",
      "3. Not understanding how the YouTube algorithm works.\n",
      "4. Not researching the best niche for YouTube automation.\n",
      "5. Not optimizing the About section with relevant keywords.\n",
      "6. Not creating a logo and channel art that is professional and attractive.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What some YouTube automation mistakes to avoid?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a05da",
   "metadata": {},
   "source": [
    "# Chatbot Class - Just include your index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a0e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, api_key, index):\n",
    "        self.index = index\n",
    "        openai.api_key = api_key\n",
    "        self.chat_history = []\n",
    "\n",
    "    def generate_response(self, user_input):\n",
    "        prompt = \"\\n\".join([f\"{message['role']}: {message['content']}\" for message in self.chat_history[-5:]])\n",
    "        prompt += f\"\\nUser: {user_input}\"\n",
    "        response = index.query(user_input)\n",
    "\n",
    "        message = {\"role\": \"assistant\", \"content\": response.response}\n",
    "        self.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.chat_history.append(message)\n",
    "        return message\n",
    "    \n",
    "    def load_chat_history(self, filename):\n",
    "        try:\n",
    "            with open(filename, 'r') as f:\n",
    "                self.chat_history = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    def save_chat_history(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.chat_history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./data').load_data()\n",
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24576df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap out your index below for whatever knowledge base you want\n",
    "bot = Chatbot(\"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\", index=index)\n",
    "bot.load_chat_history(\"chat_history.json\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"bye\", \"goodbye\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        bot.save_chat_history(\"chat_history.json\")\n",
    "        break\n",
    "    response = bot.generate_response(user_input)\n",
    "    print(f\"Bot: {response['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
